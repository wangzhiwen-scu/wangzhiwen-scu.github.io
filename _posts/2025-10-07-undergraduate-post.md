---
title: '本科实习'
date: 2025-10-07
permalink: /posts/2025/10/undergraduate-research/
tags:
  - 本科生科研
  - 实习
  - 训练营
categories:
  - 科研指导
---

# 本科生三阶段的科研训练

对于本科进组实习和训练的同学，老师着手打造计科院**多模态科学计算学生创新团队**，未来将在团委注册成实验室直属的实体社团：**多模态科学计算开源社团**，一个机构两个名称（方便对外对内交流）。目前所有报名同学默认加入拟成立的**社团**成为会员，并接受**练习训练营**三阶段的科研训练，训练合格者（不难，主要在于持之以恒的坚持）将成为资深会员，训练最优秀者可立即推荐到香港理工大学、梅奥诊所（Mayo Clinic）等顶级科研机构接受指导。社团未来将形成大三、大二、大一的传帮带氛围，用于培养和选拔学有余力并有志于进组实习的科研后备人才。不认可此种培训方式的同学可退出。

练习训练营旨在于选拔并培养具有坚韧的意志品格、强烈的科研兴趣、出色的学习能力的同学，并为之提供为期数月到数年的科研培育，不卡学分绩点档次，也不关心年级排名。对于成功完成练习训练并成为资深会员的同学，实验室会提供必要的资源以及专业的生涯规划指导，并在导师的指导下开展科研工作、参与各类竞赛。如资深会员将由老师指导参加CVPR、MICCAI、KAGGLE、ISBI等会议/组织举办的学术竞赛、互联网+等创新创业比赛、发明专利和SCI论文发表。

**科研补助费用只在完成相关竞赛或论文等科研产出后进行专项补助，介意者可以退出此次培训营。**

与此同时，我们也要求参与**练习训练营**的同学，必须是学有余力的，能够保证学习时间，不能影响正常上课，原则上平时没课时间和寒暑假大多数时间都需要投入到学习相关工作之中。如果在完成新芽训练营之后，有因为课程学习、出国申请、其他 Group 实习等各种原因在内的任何理由，会长期暂停或者放弃实习的，请提前告知，我们会将名额和资源优先给其他学生。万事诚信第一。

目前，练习训练营共有三个阶段，分别是“播种期”、“萌芽期”和“培育期”。

第一阶段：播种期。在第一阶段“播种期”，对于编程零基础者（计科院大一或其他学院大二大三同学），我们要求申请者自学《Python》(https://www.runoob.com/python3 )、《动手学深度学习》（https://zh.d2l.ai/ ）、《CS231n: Deep Learning for Computer Vision》（https://cs231n.stanford.edu/ ） 等课程来夯实基础。申请人需要每周打卡汇报上一周的学习进展，若长期缺席，则视为自愿放弃并从训练营中移除。请勿使用与训练内容无关的内容或者大模型生成的内容来搪塞打卡、凑够打卡次数，我们有核查机制，万事诚信第一。注：大二同学若有相关编程基础，可跳过该期。大一同学必须从该阶段开始，若有大一编程基础较好，可缩短该阶段。《Python》预估用时2周，自学并文字汇报即可；《动手学深度学习》预估用时6周，并在github上建立仓库完成作业；《CS231n: Deep Learning for Computer Vision》预估用时6周，并在github上建立仓库完成作业。

第二阶段：萌芽期。在第二阶段“萌芽期”，我们要求从给定的 21 个论文主题集合中挑选 1 个，每个主题包含 10 篇以上工作。选定主题后，申请人需要每周打卡汇报上一周的学习进展并在**github上更新完成相关复现**，并在看完一篇论文后用**做复现实验和总结，并用overleaf写成latex，分享overleaf地址在周报中**。若长期缺席，则视为自愿放弃并从训练营中移除。再次提醒：请勿使用与训练内容无关的内容或者大模型生成的内容来搪塞打卡、凑够打卡次数，我们有核查机制，万事诚信第一。

详细合集论文请参考：https://pan.baidu.com/s/1mcKWP4gdD9PR6thPvKnVGw?pwd=grok

打卡内容示范：

> 本周：按照李沐老师课程的顺序回顾了上学期中已学习过的一些简单的神经网络的内容：从最基本的线性回归开始，到softmax回归，多层感知机和CNN中最基础的知识且又动手从零开始构建，本期学习项目地址：github.com/xxxx/。在回顾的过程中收获颇丰，不仅加深了记忆，也对当时遗留下来的一些问题又有了一些新的理解。同时最初步的阅读了一下所选主题中一篇关于LoRA的论文，从论文中了解到随着模型规模的不断增大，全参数微调变的不再可行，取而代之是LoRA的思想:冻结原矩阵，引入一个可训练的矩阵并对其进行低秩分解以只训练较少的参数。   
> 下周目标：继续推进李沐老师的课程的学习；学习论文中所提到的transformer架构以及其前置知识；继续理解这篇论文的公式及其原理。

打卡满 12 次（github提交不得少于10次，latex提交不得少于10次）且打卡率超过 85% 的同学可以申请结业口头汇报，包含至少 4 篇研究工作（综述论文除外）的详细阅读与技术细节梳理，其中 3 篇来自该主题集合，1 篇可由申请人自主从互联网上搜索该主题上最新发布/发表的重要论文。萌芽期结题汇报的质量，请至少对齐示例，如下：

1. 通用架构 or 绑定下游？浅谈多模态图像融合的发展（https://www.bilibili.com/video/BV189JizDEvw/ ）
2. Large Language Model Agent（https://www.bilibili.com/video/BV1bLJizmE9D/ ）
3. 从线性叠加到语义融合：mixup 技术的演进（https://www.bilibili.com/video/BV1jg4y1f7Vj/ ）

需要提醒的是，分配的论文阅读任务在数量和难度上都颇具挑战，相当于一次研究生 Seminar 汇报的工作强度。推荐第二阶段的同学可随时复习自学《动手学深度学习》（https://zh.d2l.ai/ ）、《CS231n: Deep Learning for Computer Vision》（https://cs231n.stanford.edu/ ）等课程来夯实基础。温故知新。

第三阶段：培育期。萌芽期结业答辩会有评委打分，均分大于 85 的同学进入第三阶段培育期，重点培育和考察动手编程的能力，此阶段会有组内的老师和研究生给与适当的指导和答疑。我们希望同学能够从第一轮所选主题的相关论文中，选择一篇论文用国产的 Jittor 框架（https://github.com/Jittor/jittor ）进行实现并开源在个人 Github 上。第二轮代码面试的 Jittor 代码开源链接，请将环境配置、数据准备脚本、训练脚本、测试脚本、与 PyTorch 实现对齐的实验 Log、性能 Log 都放在 README 中。如果计算资源有限，用少量数据的训练效果和 PyTorch 版本的结果对齐。请将训练过程 Log、Loss 曲线，结果等对齐情况进行记录。并在overleaf 上用latex完成相关报告攥写。

有志于来本组学习并自信可以完成三阶段训练的同学，可给老师发邮件（paprikatree at foxmail dot com），并附上简历。大一的同学请在有飞书之后开始报名。后续有社团实体后，可接受线下报名。

##  关于学术标准
课题组鼓励学生深挖重要的科研问题，注重论文质量而非数量。建议学生们花更多的时间去打造一个对整个科研共同体有用的项目，而非持续的发很多论文。因此团队本身不对进组的论文数做任何要求。

实验室要求学生严格遵守学术规范。所有发表论文，除有特殊项目保密约定，都要将学术成果开源。在读期间发现存在学术不端行为（禁止任何形式的抄袭与复制），不管是有意还是不良习惯导致的无意结果，都将失去毕业的可能（研究生）。除上述极端情况以外，符合学校最低毕业要求的同学都会按照学校正常年限顺利毕业。

郑重声明：本课题组禁止任何形式的抄袭与复制！禁止任何师生与那些未开源论文代码的作者合作！任何学生未经允许不得私自开展科研合作。必须遵守该声明倡议约定，不满此规定的同学可以申请退组。

此外，对于主动的学术不端：莫伸手，伸手必后悔。为了防止被动卷入学术不端争议。特建议2个良好习惯：
> 可验证记录：为了防止同期工作产生争议，在不违反保密协议的情况下，我们应该用第三方带有时间戳记录的平台保留关键节点。同时利用密码保护自己的知识产权和私有数据。  
> 可信合作者：不与曾经有过主动学术不端行为的作者合作。最好只与有良好开源习惯的作者合作。

## 资源
### PPT
准备一个好的学术报告是研究生的必备技能。在报告中，应该做到深入浅出，表达清晰。深入浅出是指，不要假设读者群体有过多的背景知识，越是能让更广泛的群体听懂的报告，通常越体现报告人水平。此外，报告格式也切忌自己只有自己能看懂。很多重要的答辩由于场地限制，很可能重要的听众坐的比较远且视力不太好，建议每页PPT不要有太多内容。切忌把Power Point做成Power Sentence，更不要做成Power Paragraph。为了方便组内交流和各种资料的快速整合。建议课题组同学做PPT尽量用这个模板([百度网盘](https://pan.baidu.com/s/1DzmR-5dXtwVJPRxZwtFH2w?pwd=mu7p) )。所有希望读者看清楚的内容，都不要比模板中二级标题的字体小。

### 学术论文资源-LaTeX写作示例:
LaTeX是论文写作与管理格式规范的重要工具。最简单快速的上手办法就是从样例开始学起，照猫画虎。
- Res2Net: A New Multi-scale Backbone Architecture, Shang-Hua Gao, Ming-Ming Cheng, Kai Zhao, Xin-Yu Zhang, Ming-Hsuan Yang, Philip Torr, IEEE TPAMI, 2020. [pdf](http://mftp.mmcheng.net/Papers/19pami_res2net.pdf)、[code](https://github.com/gasvn/Res2Net)、[pptx](http://mftp.mmcheng.net/Papers/20Res2Net.pptx)、[project](https://mmcheng.net/res2net/)、[LaTeX](https://www.overleaf.com/read/zqttbzknmjrz)
- Global Contrast based Salient Region Detection. Ming-Ming Cheng, Niloy J. Mitra, Xiaolei Huang, Philip H. S. Torr, Shi-Min Hu. IEEE TPAMI, 37(3), 569-582, 2015.  [pdf](https://mmcheng.net/mftp/Papers/SaliencyTPAMI.pdf)、[project](https://mmcheng.net/SalObj/)、[bib](https://mmcheng.net/mftp/Papers/SaliencyObj.txt)、[LaTex](https://www.overleaf.com/read/tmckznsgbknh)、[Overleaf Latex 中文版](https://www.overleaf.com/read/rzdpjzqwkdwb) 
- 图像内容的显著性与相似性研究, 程明明, 清华大学博士学位论文, 2012.  [pdf](https://mmcheng.net/mftp/Papers/CmmPhdThesis.pdf)、[latex](https://mmcheng.net/mftp/Papers/CmmThesisLatex.zip)、[bib](https://mmcheng.net/mftp/Papers/CmmPhdThesis.txt)、[slides](http://mftp.mmcheng.net/Reports/2020CmmPhD.pptx)

Thanks to CMM!

### 学习论文和代码尝试用大模型进行**辅助**:
大模型排行榜：https://lmarena.ai/leaderboard

论文辅助：
阅读论文需要自己仔细学习，大模型仅仅起到辅助功能，你的上限决定了大模型的上限！坚决不能用大模型提交汇报。
- 国内：DeepSeek，kimi，通义千问等
- 国外：ChatGPT，Grok，Gemini等

代码（Vibe coding）辅助，切记，大模型辅助编程仅用于辅助编程和辅助学习！学习编程还是需要古法手工编程！再次提醒，你的上限决定了大模型的上限！坚决不能用大模型提交汇报。编辑器建议使用vscode。
- Cursor（需订阅）
- vscode + kimi api + cline等（国内cursor平替）
    - https://platform.moonshot.cn/docs/overview
    - https://platform.moonshot.cn/docs/guide/agent-support#%E5%AE%98%E6%96%B9%E6%8E%A8%E8%8D%90%E9%85%8D%E7%BD%AE-moonshot-provider-%E4%BD%BF%E7%94%A8-kimi-k2-%E6%A8%A1%E5%9E%8B
- Gemini Cli
- Copilot
- codex
- 其他等

### 博客学习:
- 苏剑林博客（人工智能相关的数学部分）: [科学空间](https://spaces.ac.cn/)
- huggingface、model 魔搭社区、pytorch tutorial

部分方向论文复现需要较好的显卡，可在多个云平台上自行租赁：如，[automl](www.autodl.com), [仙宫云](https://www.xiangongyun.com/)等性价比高的云平台。
